{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "To be delivered until 2022/01/24 23:59:59."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Arduino\n",
    "\n",
    "You will start by setting up a series of connections in order to extract some data with the Arduino. First make the connections as shown below. **Mind the direction of the temperature sensor. If you have an incorrect position, you will be connection the power to the ground and vice-versa and you will damage the sensor.** The photoresistor sensor on the other hand has no polarity.\n",
    "\n",
    "<img src=\"temp_photo_cropped.png\" width=1000/>\n",
    "\n",
    "On this problem, you will read temperature and luminance from the sensors and print them on the serial.\n",
    "\n",
    "**1)** Code an Arduino sketch, where the value of temperature and luminance are printed to the serial. For each serial print that you make, print the value of temperature, then a semicolon, then the value of luminance with a new line (use no whitespaces). You can do this by using three separate `Serial.print`, with the last one being a `Serial.println`. Print values 5 times per second (use the delay function to control this). Manually influence the readings of the sensors, by covering the photoresistor or shining light on it, and by lightly and carefully touching the temperature sensor to increase its temperature readings.\n",
    "\n",
    "**Note that the temperature sensor appears not to be very reliable. Since the objective of this exercise is just to plot the results, this should not be an issue.**\n",
    "\n",
    "**Copy and paste your arduino code below. You may use a python code cell, even though the code can not be run.**\n",
    "\n",
    "*Hint: for the temperature value to be in celsius, divide the read value by 1024 and multiply it by 500. The luminance does not have to be converted*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To import the data into Arduino, keep it running (the Serial Monitor must be closed in Arduino) and run the following code. Change the COM port to your own. This block of code will read 1000 values from the Serial. Given that each observation is taken every 0.2 seconds, it should take a minute and a half."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import serial\n",
    "import time\n",
    "\n",
    "ser = serial.Serial('COM4', 9600, timeout=1)\n",
    "time.sleep(2)\n",
    "\n",
    "data = []\n",
    "for i in range(500):\n",
    "    line = ser.readline()\n",
    "    if line:\n",
    "        string = line.decode()\n",
    "        data.append(string)\n",
    "\n",
    "ser.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the data into a pandas dataframe and save it in a csv file. Besides the value of temperature and luminance, also include the time, considering the first observation at $t=0$ and every observation 0.2 seconds after the previous one. **The file must be submitted in Fenix and included in your Github repo**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the Temperature against time, the luminance against time and the temperature against the luminance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Databases\n",
    "\n",
    "For the databases part of this assignment, you will use the mimic-iii database from the laboratory session. Start by adding a few new tables to the database, using the SQL files included in the assignment's files. Open PGAdmin and connect to your mimic-iii database. **To properly load these tables, load the following files exactly and by the order presented.**\n",
    "\n",
    "1) Run demographic.sql\n",
    "\n",
    "2) Run lab_firstday.sql\n",
    "\n",
    "You will now have to answer a few SQL questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** Open the connection to your mimic-iii database. If you want, you can delete your credentials before submitting the assignment, but if you do so, please run the notebook first, for the results to be displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection established to:  ('PostgreSQL 14.1, compiled by Visual C++ build 1914, 64-bit',)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2 as psql\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "conn = psql.connect(host='localhost',\n",
    "                    database='mimic-iii',\n",
    "                    user='username',\n",
    "                    password='password',\n",
    "                    port=5432)\n",
    "\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"select version()\")\n",
    "data = cursor.fetchone()\n",
    "\n",
    "print(\"Connection established to: \", data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.** Create a function that receives an SQL query and automatically opens a cursor, queries the database, extracts the columns, creates a pandas database, and closes the connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2 as psql\n",
    "def receive_query( query ):\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(query)\n",
    "    colnames = [desc[0] for desc in cursor.description]\n",
    "    data = cursor.fetchall()\n",
    "    query_table = pd.DataFrame(data, columns = colnames)\n",
    "    print(query_table)\n",
    "    conn.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.** Query the table admissions filtering for admission type as elective and insurance as private."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>admittime</th>\n",
       "      <th>dischtime</th>\n",
       "      <th>deathtime</th>\n",
       "      <th>admission_type</th>\n",
       "      <th>admission_location</th>\n",
       "      <th>discharge_location</th>\n",
       "      <th>insurance</th>\n",
       "      <th>language</th>\n",
       "      <th>religion</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>edregtime</th>\n",
       "      <th>edouttime</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>hospital_expire_flag</th>\n",
       "      <th>has_chartevents_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12315</td>\n",
       "      <td>10065</td>\n",
       "      <td>183314</td>\n",
       "      <td>2189-09-08 07:15:00</td>\n",
       "      <td>2189-09-20 14:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>ELECTIVE</td>\n",
       "      <td>PHYS REFERRAL/NORMAL DELI</td>\n",
       "      <td>SNF</td>\n",
       "      <td>Private</td>\n",
       "      <td>ENGL</td>\n",
       "      <td>CATHOLIC</td>\n",
       "      <td>SINGLE</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ESOPHAGEAL CANCER/SDA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40972</td>\n",
       "      <td>43798</td>\n",
       "      <td>130870</td>\n",
       "      <td>2198-06-29 07:15:00</td>\n",
       "      <td>2198-08-07 23:59:00</td>\n",
       "      <td>None</td>\n",
       "      <td>ELECTIVE</td>\n",
       "      <td>PHYS REFERRAL/NORMAL DELI</td>\n",
       "      <td>HOME HEALTH CARE</td>\n",
       "      <td>Private</td>\n",
       "      <td>ENGL</td>\n",
       "      <td>CATHOLIC</td>\n",
       "      <td>MARRIED</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ESOPHAGEAL CA/SDA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41053</td>\n",
       "      <td>44083</td>\n",
       "      <td>125157</td>\n",
       "      <td>2112-05-04 08:00:00</td>\n",
       "      <td>2112-05-11 14:15:00</td>\n",
       "      <td>None</td>\n",
       "      <td>ELECTIVE</td>\n",
       "      <td>PHYS REFERRAL/NORMAL DELI</td>\n",
       "      <td>HOME HEALTH CARE</td>\n",
       "      <td>Private</td>\n",
       "      <td>ENGL</td>\n",
       "      <td>CATHOLIC</td>\n",
       "      <td>SINGLE</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ESOPHAGEAL CA/SDA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id  subject_id  hadm_id           admittime           dischtime  \\\n",
       "0   12315       10065   183314 2189-09-08 07:15:00 2189-09-20 14:00:00   \n",
       "1   40972       43798   130870 2198-06-29 07:15:00 2198-08-07 23:59:00   \n",
       "2   41053       44083   125157 2112-05-04 08:00:00 2112-05-11 14:15:00   \n",
       "\n",
       "  deathtime admission_type         admission_location discharge_location  \\\n",
       "0      None       ELECTIVE  PHYS REFERRAL/NORMAL DELI                SNF   \n",
       "1      None       ELECTIVE  PHYS REFERRAL/NORMAL DELI   HOME HEALTH CARE   \n",
       "2      None       ELECTIVE  PHYS REFERRAL/NORMAL DELI   HOME HEALTH CARE   \n",
       "\n",
       "  insurance language  religion marital_status ethnicity edregtime edouttime  \\\n",
       "0   Private     ENGL  CATHOLIC         SINGLE     WHITE      None      None   \n",
       "1   Private     ENGL  CATHOLIC        MARRIED     WHITE      None      None   \n",
       "2   Private     ENGL  CATHOLIC         SINGLE     WHITE      None      None   \n",
       "\n",
       "               diagnosis  hospital_expire_flag  has_chartevents_data  \n",
       "0  ESOPHAGEAL CANCER/SDA                     0                     1  \n",
       "1      ESOPHAGEAL CA/SDA                     0                     1  \n",
       "2      ESOPHAGEAL CA/SDA                     0                     1  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtering = \"SELECT * FROM public.admissions WHERE admission_type = 'ELECTIVE' AND insurance = 'Private'\"\n",
    "cursor.execute(filtering)\n",
    "\n",
    "colnames = [desc[0] for desc in cursor.description]\n",
    "data = cursor.fetchall()\n",
    "\n",
    "\n",
    "\n",
    "filtered_table = pd.DataFrame(data, columns = colnames)\n",
    "filtered_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.** Query the table admissions, filtering for the same conditions as the previous exercise (admission type as elective and insurance as private). Join the \"drgcodes\" table on the admission ID. Display only the columns regarding the subject id, admission id, time of death, and description of the drug."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>admission_type</th>\n",
       "      <th>deathtime</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10065</td>\n",
       "      <td>183314</td>\n",
       "      <td>None</td>\n",
       "      <td>Major Stomach, Esophageal &amp; Duodenal Procedures</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10065</td>\n",
       "      <td>183314</td>\n",
       "      <td>None</td>\n",
       "      <td>STOMACH, ESOPHAGEAL &amp; DUODENAL PROC AGE &gt;17 W ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43798</td>\n",
       "      <td>130870</td>\n",
       "      <td>None</td>\n",
       "      <td>Tracheostomy W Long Term Mechanical Ventilatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43798</td>\n",
       "      <td>130870</td>\n",
       "      <td>None</td>\n",
       "      <td>Tracheostomy W Long Term Mechanical Ventilatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43798</td>\n",
       "      <td>130870</td>\n",
       "      <td>None</td>\n",
       "      <td>TRACH W MV 96+ HRS OR PDX EXC FACE, MOUTH &amp; NE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>44083</td>\n",
       "      <td>125157</td>\n",
       "      <td>None</td>\n",
       "      <td>Major Stomach, Esophageal &amp; Duodenal Procedures</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>44083</td>\n",
       "      <td>125157</td>\n",
       "      <td>None</td>\n",
       "      <td>Major Stomach, Esophageal &amp; Duodenal Procedures</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>44083</td>\n",
       "      <td>125157</td>\n",
       "      <td>None</td>\n",
       "      <td>STOMACH, ESOPHAGEAL &amp; DUODENAL PROC W MCC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id  admission_type deathtime  \\\n",
       "0       10065          183314      None   \n",
       "1       10065          183314      None   \n",
       "2       43798          130870      None   \n",
       "3       43798          130870      None   \n",
       "4       43798          130870      None   \n",
       "5       44083          125157      None   \n",
       "6       44083          125157      None   \n",
       "7       44083          125157      None   \n",
       "\n",
       "                                         description  \n",
       "0    Major Stomach, Esophageal & Duodenal Procedures  \n",
       "1  STOMACH, ESOPHAGEAL & DUODENAL PROC AGE >17 W ...  \n",
       "2  Tracheostomy W Long Term Mechanical Ventilatio...  \n",
       "3  Tracheostomy W Long Term Mechanical Ventilatio...  \n",
       "4  TRACH W MV 96+ HRS OR PDX EXC FACE, MOUTH & NE...  \n",
       "5    Major Stomach, Esophageal & Duodenal Procedures  \n",
       "6    Major Stomach, Esophageal & Duodenal Procedures  \n",
       "7          STOMACH, ESOPHAGEAL & DUODENAL PROC W MCC  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined = \"SELECT admissions.subject_id, admissions.hadm_id as admission_type, deathtime, drgcodes.description FROM admissions LEFT JOIN drgcodes ON admissions.hadm_id = drgcodes.hadm_id WHERE insurance = 'Private' and admission_type = 'ELECTIVE';\"\n",
    "cursor.execute(joined)\n",
    "\n",
    "colnames = [desc[0] for desc in cursor.description]\n",
    "data2 = cursor.fetchall()\n",
    "\n",
    "\n",
    "joined_table = pd.DataFrame(data2, columns = colnames)\n",
    "joined_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.1.** Obtain the dataset for this problem, by running the SQL query below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>icustay_id</th>\n",
       "      <th>aniongap_min</th>\n",
       "      <th>aniongap_max</th>\n",
       "      <th>albumin_min</th>\n",
       "      <th>albumin_max</th>\n",
       "      <th>bands_min</th>\n",
       "      <th>bands_max</th>\n",
       "      <th>bicarbonate_min</th>\n",
       "      <th>...</th>\n",
       "      <th>sodium_max</th>\n",
       "      <th>bun_min</th>\n",
       "      <th>bun_max</th>\n",
       "      <th>wbc_min</th>\n",
       "      <th>wbc_max</th>\n",
       "      <th>gender</th>\n",
       "      <th>admission_age</th>\n",
       "      <th>eth_grp</th>\n",
       "      <th>hospital_expire_flag</th>\n",
       "      <th>los_icu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10006</td>\n",
       "      <td>142345</td>\n",
       "      <td>206504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>139.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>7.8</td>\n",
       "      <td>F</td>\n",
       "      <td>70.0</td>\n",
       "      <td>black</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10011</td>\n",
       "      <td>105331</td>\n",
       "      <td>232110</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>...</td>\n",
       "      <td>136.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>10.6</td>\n",
       "      <td>F</td>\n",
       "      <td>36.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10013</td>\n",
       "      <td>165520</td>\n",
       "      <td>264446</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>138.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>13.8</td>\n",
       "      <td>16.2</td>\n",
       "      <td>F</td>\n",
       "      <td>87.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10017</td>\n",
       "      <td>199207</td>\n",
       "      <td>204881</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>139.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.8</td>\n",
       "      <td>15.8</td>\n",
       "      <td>F</td>\n",
       "      <td>74.0</td>\n",
       "      <td>white</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10019</td>\n",
       "      <td>177759</td>\n",
       "      <td>228977</td>\n",
       "      <td>20.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>141.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>6.8</td>\n",
       "      <td>M</td>\n",
       "      <td>49.0</td>\n",
       "      <td>white</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>44083</td>\n",
       "      <td>198330</td>\n",
       "      <td>286428</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>142.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.3</td>\n",
       "      <td>14.9</td>\n",
       "      <td>M</td>\n",
       "      <td>55.0</td>\n",
       "      <td>white</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>44154</td>\n",
       "      <td>174245</td>\n",
       "      <td>217724</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>142.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>17.1</td>\n",
       "      <td>M</td>\n",
       "      <td>300.0</td>\n",
       "      <td>white</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>44212</td>\n",
       "      <td>163189</td>\n",
       "      <td>239396</td>\n",
       "      <td>15.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>150.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>8.8</td>\n",
       "      <td>11.4</td>\n",
       "      <td>F</td>\n",
       "      <td>45.0</td>\n",
       "      <td>black</td>\n",
       "      <td>0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>44222</td>\n",
       "      <td>192189</td>\n",
       "      <td>238186</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>135.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>9.3</td>\n",
       "      <td>9.9</td>\n",
       "      <td>M</td>\n",
       "      <td>73.0</td>\n",
       "      <td>white</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>44228</td>\n",
       "      <td>103379</td>\n",
       "      <td>217992</td>\n",
       "      <td>12.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>142.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>41.9</td>\n",
       "      <td>F</td>\n",
       "      <td>58.0</td>\n",
       "      <td>white</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     subject_id  hadm_id  icustay_id  aniongap_min  aniongap_max  albumin_min  \\\n",
       "0         10006   142345      206504          12.0          20.0          2.7   \n",
       "1         10011   105331      232110          12.0          12.0          2.6   \n",
       "2         10013   165520      264446          13.0          13.0          NaN   \n",
       "3         10017   199207      204881          13.0          13.0          2.8   \n",
       "4         10019   177759      228977          20.0          46.0          3.2   \n",
       "..          ...      ...         ...           ...           ...          ...   \n",
       "123       44083   198330      286428          16.0          16.0          NaN   \n",
       "124       44154   174245      217724          15.0          15.0          NaN   \n",
       "125       44212   163189      239396          15.0          21.0          2.9   \n",
       "126       44222   192189      238186          11.0          15.0          NaN   \n",
       "127       44228   103379      217992          12.0          18.0          2.2   \n",
       "\n",
       "     albumin_max  bands_min  bands_max  bicarbonate_min  ...  sodium_max  \\\n",
       "0            3.4        NaN        NaN             29.0  ...       139.0   \n",
       "1            2.6        2.0        2.0             23.0  ...       136.0   \n",
       "2            NaN       13.0       13.0             29.0  ...       138.0   \n",
       "3            2.8        NaN        NaN             29.0  ...       139.0   \n",
       "4            3.2        NaN        NaN             10.0  ...       141.0   \n",
       "..           ...        ...        ...              ...  ...         ...   \n",
       "123          NaN        NaN        NaN             21.0  ...       142.0   \n",
       "124          NaN        NaN        NaN             19.0  ...       142.0   \n",
       "125          3.0        NaN        NaN             18.0  ...       150.0   \n",
       "126          NaN        NaN        NaN             22.0  ...       135.0   \n",
       "127          2.7        NaN        NaN             15.0  ...       142.0   \n",
       "\n",
       "     bun_min  bun_max  wbc_min  wbc_max  gender  admission_age  eth_grp  \\\n",
       "0        9.0     11.0      4.6      7.8       F           70.0    black   \n",
       "1        3.0      3.0     10.6     10.6       F           36.0  unknown   \n",
       "2       32.0     32.0     13.8     16.2       F           87.0  unknown   \n",
       "3        3.0      3.0     15.8     15.8       F           74.0    white   \n",
       "4       31.0     53.0      3.7      6.8       M           49.0    white   \n",
       "..       ...      ...      ...      ...     ...            ...      ...   \n",
       "123     12.0     12.0     12.3     14.9       M           55.0    white   \n",
       "124     16.0     21.0     12.2     17.1       M          300.0    white   \n",
       "125     37.0     57.0      8.8     11.4       F           45.0    black   \n",
       "126     21.0     24.0      9.3      9.9       M           73.0    white   \n",
       "127     10.0     11.0      7.0     41.9       F           58.0    white   \n",
       "\n",
       "     hospital_expire_flag  los_icu  \n",
       "0                       0      1.0  \n",
       "1                       1     13.0  \n",
       "2                       1      2.0  \n",
       "3                       0      2.0  \n",
       "4                       1      1.0  \n",
       "..                    ...      ...  \n",
       "123                     0      3.0  \n",
       "124                     1      0.0  \n",
       "125                     0     31.0  \n",
       "126                     0      1.0  \n",
       "127                     0      4.0  \n",
       "\n",
       "[128 rows x 46 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = \"SELECT pivoted_lab.*,\" +\\\n",
    "                \"gender as gender,\" +\\\n",
    "                \"admission_age,\" +\\\n",
    "                \"ethnicity_grouped as eth_grp,\" +\\\n",
    "                \"hospital_expire_flag,\" +\\\n",
    "                \"los_icu \" +\\\n",
    "        \"FROM demographics \" +\\\n",
    "        \"LEFT JOIN pivoted_lab \" +\\\n",
    "        \"ON demographics.icustay_id = pivoted_lab.icustay_id \" +\\\n",
    "        \"WHERE first_icu_stay = true\"\n",
    "cursor.execute(dataset)\n",
    "\n",
    "colnames = [desc[0] for desc in cursor.description]\n",
    "data3 = cursor.fetchall()\n",
    "\n",
    "\n",
    "dataset_table = pd.DataFrame(data3, columns = colnames)\n",
    "dataset_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.2.** Close the connection to your SQL server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.3.** Prepare your dataset:\n",
    "\n",
    "* Drop the ID columns of subject, admission and ICU stay.\n",
    "* Drop columns with at least one NA value.\n",
    "* Encode the categorical columns, the ethnicity and gender ('eth_grp', 'gender'). *Suggestion: use pd.get_dummies*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bicarbonate_min</th>\n",
       "      <th>bicarbonate_max</th>\n",
       "      <th>creatinine_min</th>\n",
       "      <th>creatinine_max</th>\n",
       "      <th>chloride_min</th>\n",
       "      <th>chloride_max</th>\n",
       "      <th>glucose_min</th>\n",
       "      <th>glucose_max</th>\n",
       "      <th>hematocrit_min</th>\n",
       "      <th>hematocrit_max</th>\n",
       "      <th>...</th>\n",
       "      <th>los_icu</th>\n",
       "      <th>eth_grp_asian</th>\n",
       "      <th>eth_grp_black</th>\n",
       "      <th>eth_grp_hispanic</th>\n",
       "      <th>eth_grp_native</th>\n",
       "      <th>eth_grp_other</th>\n",
       "      <th>eth_grp_unknown</th>\n",
       "      <th>eth_grp_white</th>\n",
       "      <th>gender_F</th>\n",
       "      <th>gender_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>96.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>36.9</td>\n",
       "      <td>42.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>107.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>33.9</td>\n",
       "      <td>34.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.7</td>\n",
       "      <td>98.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>29.2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>27.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>83.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>30.6</td>\n",
       "      <td>36.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>108.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>107.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>40.8</td>\n",
       "      <td>41.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>18.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>108.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>23.8</td>\n",
       "      <td>25.9</td>\n",
       "      <td>...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>22.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.7</td>\n",
       "      <td>100.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>37.8</td>\n",
       "      <td>39.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>15.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>103.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>22.6</td>\n",
       "      <td>27.6</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     bicarbonate_min  bicarbonate_max  creatinine_min  creatinine_max  \\\n",
       "0               29.0             31.0             3.0             3.5   \n",
       "1               23.0             23.0             0.7             0.7   \n",
       "2               29.0             29.0             1.7             1.7   \n",
       "3               29.0             29.0             0.3             0.3   \n",
       "4               10.0             18.0             4.0             7.2   \n",
       "..               ...              ...             ...             ...   \n",
       "123             21.0             21.0             0.7             0.7   \n",
       "124             19.0             19.0             0.9             0.9   \n",
       "125             18.0             23.0             3.0             4.8   \n",
       "126             22.0             27.0             1.2             1.7   \n",
       "127             15.0             24.0             0.6             0.8   \n",
       "\n",
       "     chloride_min  chloride_max  glucose_min  glucose_max  hematocrit_min  \\\n",
       "0            96.0         100.0         84.0        217.0            36.9   \n",
       "1           107.0         107.0         79.0         79.0            33.9   \n",
       "2            98.0         100.0        134.0        165.0            28.1   \n",
       "3           100.0         100.0        137.0        137.0            27.5   \n",
       "4            83.0         104.0         80.0        360.0            30.6   \n",
       "..            ...           ...          ...          ...             ...   \n",
       "123         108.0         108.0        151.0        151.0            26.0   \n",
       "124         107.0         113.0        164.0        177.0            40.8   \n",
       "125         108.0         115.0         99.0        122.0            23.8   \n",
       "126         100.0         101.0         56.0        268.0            37.8   \n",
       "127         103.0         115.0         91.0        132.0            22.6   \n",
       "\n",
       "     hematocrit_max  ...  los_icu  eth_grp_asian  eth_grp_black  \\\n",
       "0              42.4  ...      1.0              0              1   \n",
       "1              34.0  ...     13.0              0              0   \n",
       "2              29.2  ...      2.0              0              0   \n",
       "3              27.5  ...      2.0              0              0   \n",
       "4              36.0  ...      1.0              0              0   \n",
       "..              ...  ...      ...            ...            ...   \n",
       "123            29.0  ...      3.0              0              0   \n",
       "124            41.8  ...      0.0              0              0   \n",
       "125            25.9  ...     31.0              0              1   \n",
       "126            39.0  ...      1.0              0              0   \n",
       "127            27.6  ...      4.0              0              0   \n",
       "\n",
       "     eth_grp_hispanic  eth_grp_native  eth_grp_other  eth_grp_unknown  \\\n",
       "0                   0               0              0                0   \n",
       "1                   0               0              0                1   \n",
       "2                   0               0              0                1   \n",
       "3                   0               0              0                0   \n",
       "4                   0               0              0                0   \n",
       "..                ...             ...            ...              ...   \n",
       "123                 0               0              0                0   \n",
       "124                 0               0              0                0   \n",
       "125                 0               0              0                0   \n",
       "126                 0               0              0                0   \n",
       "127                 0               0              0                0   \n",
       "\n",
       "     eth_grp_white  gender_F  gender_M  \n",
       "0                0         1         0  \n",
       "1                0         1         0  \n",
       "2                0         1         0  \n",
       "3                1         1         0  \n",
       "4                1         0         1  \n",
       "..             ...       ...       ...  \n",
       "123              1         0         1  \n",
       "124              1         0         1  \n",
       "125              0         1         0  \n",
       "126              1         0         1  \n",
       "127              1         1         0  \n",
       "\n",
       "[128 rows x 32 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummies = pd.get_dummies(dataset_table[['eth_grp', 'gender']])\n",
    "dataset_table = pd.concat([dataset_table, dummies[['eth_grp_asian', 'eth_grp_black' ,'eth_grp_hispanic', 'eth_grp_native', 'eth_grp_other', 'eth_grp_unknown', 'eth_grp_white', 'gender_F', 'gender_M']]], axis=1)\n",
    "dataset_table.drop(['subject_id', 'hadm_id', 'icustay_id','eth_grp', 'gender'], inplace=True, axis=1)\n",
    "dataset_table = dataset_table.dropna(axis='columns')\n",
    "dataset_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.** Fit the following tree-based classifiers to the dataset. For each method:\n",
    "\n",
    "* Perform k-fold cross validation to evaluate the models. Consider 10 folds.\n",
    "\n",
    "* Plot the ROC curves for each fold, along with the mean ROC curve.\n",
    "\n",
    "* Calculate the mean AUC.\n",
    "\n",
    "**a.** Decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b.** Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c.** Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.1.** Perform a grid search cross-validation on the Gradient boosting methods, changing the value of the learning rate (0.01 to 0.5) and the number of estimators (50-500). Consider the mean AUC of the folds as the performance measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.2.** Plot a scatterplot of the learning rate versus the number of estimators, with the mean AUC as the color gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.1.** Perform forward stepwise selection on the dataset. Use the best parameters of the gradient boosting method obtained in **7.1.**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.2.** Compare and comment the results from **8.1.** with the features importance obtained through the grid search of queastion **7.1.**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Theoretical Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** Consider a dataset where best subset, forward stepwise and backward stepwise selection will be performed. For each of the 3 approaches, we obtain $p+1$ models, $p$ being the total number of predictors. This means that each approach has a model with 0 predictors, one with 1 predictor, one with 2 predictor, up until one model with $p$ predictors. Answer and justify the following questions:\n",
    "\n",
    "**a)** Which of the three models with $k, \\, \\forall_{k \\in [0,p]}$ predictors has the smallest training RSS?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Which of the three models with $k, \\, \\forall_{k \\in [0,p]}$ predictors has the smallest test RSS?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** Evaluate the following statements with *true* or *false*. Justify your answers.\n",
    "\n",
    "    i. The predictors in the k-variable model identified by forward stepwise selection are a subset of the predictors in the (k+1)-variable model identified by forward stepwise selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ii. The predictors in the k-variable model identified by backward stepwise selection are a subset of the predictors in the (k + 1)-variable model identified by backward stepwise selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    iii. The predictors in the k-variable model identified by backward stepwise selection are a subset of the predictors in the (k + 1)-variable model identified by forward stepwise selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    iv. The predictors in the k-variable model identified by forward stepwise selection are a subset of the predictors in the (k+1)-variable model identified by backward stepwise selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    v. The predictors in the k-variable model identified by best subset selection are a subset of the predictors in the (k + 1)-variable model identified by best subset selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.** Ridge regression tends to give similar coefficient values to correlated variables, whereas lasso regression may give substantially different coefficients to correlated variables. This questions explores this property in a simplified setting.\n",
    "\n",
    "Suppose that $n=2$, $p=2$, $x_{11} = x_{12}$, $x_{21} = x_{22}$. Moreover, suppose that $y_1 + y_2 = 0$ and $x_{11} + x_{21} = 0$ and $x_{12} + x_{22} = 0$, meaning that the estimate for the intercept in a least squares, ridge regression, or lasso regression is zero: $\\hat{\\beta} = 0$.\n",
    "\n",
    "**a)** Write the ridge regression optimization problem in this setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Prove that in this setting, the ridge regression coefficient estimates satisfy $\\hat{\\beta}_1 = \\hat{\\beta}_2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** Write the lasso regression optimization problem in this setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d)** Prove that in this setting, the lasso regression coefficients $\\hat{\\beta}_1$ and $\\hat{\\beta}_2$ are not unique, meaning that there are many possible solutions to the optimization problem in (c). Describe these solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.** Draw an example of a partition of two-dimensional feature space that could result from recursive binary splitting. Your example should contain at least six regions. Draw a decision tree corresponding to this partition. Be sure to label all aspects of your figures, including the regions R1, R2,..., the cutpoints t1, t2,..., and so forth.\n",
    "\n",
    "If you prefer you can draw it by hand or in any software and use a scan of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.** In 2 dimensions, a linear decision boundary takes the form $\\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 = 0$. Consider a nn-linear decision boundary:\n",
    "\n",
    "**a)** Sketch the curve\n",
    "\n",
    "$$(1 + X_1)^2 + (2 - X_2)^2 = 4$$\n",
    "\n",
    "Additionally, indicate on your sketch the set of points that verify the condition\n",
    "\n",
    "$$(1 + X_1)^2 + (2 - X_2)^2 > 4$$\n",
    "\n",
    "and the condition\n",
    "\n",
    "$$(1 + X_1)^2 + (2 - X_2)^2 \\leq 4$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Suppose that a classifier assigns an observation to the blue class if $(1 + X_1)^2 + (2 - X_2)^2 > 4$ and to the red class otherwise. To what class are the following observations classified? (0,0), (-1,1), (2,2), (3,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** Prove that while the decision boundary in (b) is not linear in terms of $X_1$ and $X_2$, it is linear in terms of $X_1$, $X_1^2$, $X_2$, and $X_2^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Laboratory Questions\n",
    "\n",
    "What are the advantages and disadvantages of relational dabases versus graph databases, and when should one type be preferred over the other?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
